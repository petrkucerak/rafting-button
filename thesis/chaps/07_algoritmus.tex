% Lokální makra patří do hlavního souboru, ne sem.
% Tady je mám výjimečně proto, že chci nechat hlavní soubor bez maker,
% která jsou jen pro tento dokument. Uživatelé si pravděpodobně budou
% hlavní soubor kopírovat do svého dokumentu.

\def\ctustyle{{\ssr CTUstyle}}
\def\ttb{\tt\char`\\} % pro tisk kontrolních sekvencí v tabulkách

\label[Algoritmus]
\chap Algoritmus řešící konsenzus

Kapitola specifikuje požadavky na algoritmus, popisuje známé algoritmy vhodné pro daný problém, které dává do kontextu a diskutuje jejich výhody a nevýhody. Následně detailně popisuje zvolený algoritmus pro budoucí implementaci.

\sec Požadavky na algoritmus

Od algoritmu se očekává řešení {\sbf problému konsenzu},\fnote{Pojmem problém konsenzu je myšlený problém nutnosti najít shody dvou až n procesů na specifické hodnotě. Ve vztahu k našemu tématu se jedná o shodě na logu určujícím pořadí.} respektive toho, v jakém pořadí byla tlačítka stisknuta.

Systém by měla být {\sbf distribuovaná}, tj. ve výchozím módu by měli být všechny zařízení na stejné úrovni a žádné z nich by před spuštěním algoritmu nemělo vůči jinému být ve vztahu {\em master} - {\em slave}.

{\sbf Systémem} je v kontextu této práce označován soubor hlasovací zařízení spojených pomocí bezdrátové technologie ESP-NOW.

Pojmem {\sbf distribuovaná síť}, obecně {\sbf distribuovaný systém} (DS)\fnote{Pojem {\sbf distribuovaný systém} je dále označován i zkratkou {\sbf DS}.} označujeme soubor autonomních nezávislých zařízení, která spolu komunikují skrze síť a jejich dorozumívacím prostředkem jsou zprávy. Dle Andrewa Tanenbauma se v ideálním případě celý distribuovaný systém jeví jako koherentní systém. Leslie Lamport je naopak kritičtější a říká, že pojmeme distribuovaný systém je takový, v kterém selhání počítače, o kterém jste nevěděli, že funguje, učiní užívaný počítač nepoužitelným.~\cite[DocIngCyrilKlimesCSc2014, fiRjEXokpUGbjPGS, Jakob2021-08]

Literatura se v dané terminologii rozchází a také na každý z problémů v DS jsou kladeny jiné požadavky, obecně ale můžeme řici, že rozlišujeme dva základní požadavky na DS:

\begitems
* {\sbf živost} ({\em safety}) - časem v DS bude dosažen žádoucí vztah,
* {\sbf bezpečnost} ({\em liveness}) - nedojde k nežádoucímu stavu.
\enditems

Dle {\sbf FLP teorému} v asynchronním distribuovaném systému nelze dosáhnout současně živosti a bezpečnosti distribuovaného výpočtu, pokud může docházet k selháním.~\cite[Fischer1985] V praxi se proto spíše vyžaduje bezpečnost a díky částečné synchronicitě zařízení v DS lze předpokládat, že algoritmus doběhne, tj. dosáhne výsledků v konečném čase.\fnote{Takovýto požadavek označujeme jako tzv. {\sbf {\em konečnou} živost} ({\em eventual liveness}).}~\cite[Jakob2021-13]

\secc Požadavky na distribuovaný systém

\begitems
* {\sbf Bezpečnost} - systém musí garantovat, že nedojde k nežádoucímu stavu, tj. stavu s kterým se nepočítá.
* {\sbf Konečnou živost} - není nutné, aby byl distribuovaný výpočet dokončen do určitého času. Nýbrž je požadováno dokončení výpočtu v konečném čase.
* {\sbf Uspořádání} - musí být dodrženo kauzální uspořádání v závislosti na čase, tj. musí být dodrženo pořadí.
\enditems

\sec Rozbor problému

Abstrahujme síťovou vrstvu DS a předpokládejme, že jsou všechna zařízení DS propojena, komunikace mezi nimi může ale nemusí být spolehlivá, tj. po odeslání každé zprávy může odesílatel obdržet od adresáta potvrzení, zdali byl přenos úspěšný či nikoliv. Úkolem je při stisku periferie ({\em tlačítka}) rozdistribuovat informaci do ostatních zařízení DS a určit pořadí.

Pro {\sbf určení pořadí} je třeba buďto znát {\em kauzalitu událostí}\fnote{Vědět jaké událost té druhé předcházela.} anebo umět vytvořit časovou značku pomocí hodin, které budou synchronizované v celém DS. Kauzalita událostí nám v tomto případě stačit nebude. Důvodem je to, že systém není schopen garantovat rychlost odeslání. Tedy například v momentě využití {\em Lamportových hodin}, které pracují s vektorovými nebo logickými hodinami, nejsme schopni sítí zajistit, že v momentě vzniku události ({\em stisku tlačítek}) se data rozdistribuují okamžitě. Proto při použití logického času nejsme schopni garantovat pořadí.

Systém tedy musí umět {\sbf synchronizovat hodiny} na každém zařízení. K tomuto problému by šlo využít známých protokolů, jako je například {\em Precision Time Protocol (PTP)}. V případě vhodné\fnote{Vhodnou implementací se myslí taková, která funguje jako pravý broadcast popisovaný v IEEE 8002.11, nikoli {\em pseudo broacast} popisovaný v kapitole \ref[PseudoBroadcast].} implementace broadcastu na síťové vrstvě by šlo synchronizaci značně zjednodušit. Mohla by fungovat tak, že by se v síti zvolil {\em MASTER OF TIME}, který by jednou za $n$ sekund rozeslal broadcastem čas všem zařízením v síti.

Kromě distribuce a synchronizovaného času DS musí řešit problematiku {\sbf distribuce logů} s časovými značkami. Logy je myšlena struktura, které obsahuje časovou značku, typ události v DS a popis události. Pro distribuci těchto logů je možné využít několik algoritmů diskutovaných v kapitole \ref[AlgoritmyProLogy]. 

Pro efektivní fungování síťové vrstvy by bylo vhodné, aby DS implementoval i mechanismus, který by byl schopen {\sbf distribuovat} neustále aktualizovaný {\sbf seznam zařízení} v DS.

Z krátké úvodní analýzy problému vyplývá, že algoritmus musí v DS řešit tři základní problémy:

\begitems
* synchronizaci času,
* distribuci logů,
* distribuci seznamu zařízení DS.
\enditems


\label[AlgoritmyProLogy]
\sec Srovnání možných algoritmů

\secc Synchronizace fyzických hodin (PTP, NTP)

\secc Lamportovy vektorové hodiny

\sec Problematika synchronizace času

Požadavek na přesnost synchronizace času 1 ms. Tato hodnota vychází z reakční doby člověka, která se u špičkových atletů při startu pohybuje okolo 0,1 až 0,25~s.~\cite[HwQTLhbjN4E4TuBy] Pokud tedy stanovíme hodnotu o dva řády nižší, nemělo by dojít ke kolizím. V případě kolize, která je vysoce nepravděpodobná, rozhoduje hodnota uzle (TODO: viz popis algoritmu).

\label[DatilAlgDescrp]
\secc Detailní popis zvoleného algoritmu

Doba přenosu zprávy z uzlu $N_A$ do uzlu $N_B$ trvá dobu $D_n$ s chybou $O_n$, přičemž platí, že $T_A$ je hodnota hodin v uzlu $N_A$ a $T_B$ je hodnota hodin v uzlu $N_B$. Pak o přenosu zprávy platí, že:

$$
T_A = T_B + D_n + O_n.
$$

Při fungování systému nejsme schopni zjistit absolutní hodnotu $D_n$ a $O_n$, proto počítáme s průměrovanou hodnotou ({\em aritmetický průměr}) zpoždění $\bar{D}$ a chybou počítanou klouzavým průměrem $\bar{O}$. Toto zjednodušení způsobuje nepřesnosti při synchronizaci času. Po přidání průměrných hodnot tedy platí, že:

$$
T_A = T_B + \bar{D} + \bar{O},
$$

kde doba přenosu $D_n$ je počítána jako\fnote{RTT znamená {\em round trip time}}

$$
D_n = {{RTT}\over{2}}
$$
a velikost chyby $O_n$ jako

$$
O_n = T_B - T_A - \bar{D}.
$$

Celkově algoritmus funguje tak, že z uzlu {\em MASTER} je jednou za 100 ms odešle do všech {\em SLAVE} uzlů zpráva inicializující synchronizaci {\sbf doby přenosu} a jednou za 500 ms zprávu inicializující synchronizaci {\sbf času}.

Průběh zprávy pro synchronizaci {\sbf doby přenosu} je takový, že:

\medskip
\clabel[SchemaSYNCrtt]{Schéma synchronizace doby přenosu}
\picw=16cm \cinspic img/schema-synch-rtt.png
\caption/f Schéma synchronizace doby přenosu.
\medskip

\begitems
* {\sbf [A]} Z uzlu {\em MASTER} se odešle zpráva s lokálním časem do uzlu {\em SLAVE}.
* {\sbf [B]} {\em SLAVE} uzel přijme zprávu a se stejným obsahem ji okamžitě odešle zpět do uzlu, z kterého zprávu obdržel. Tedy do uzlu typy {\em MASTER}.
* {\sbf [C]} Po obdržení času se v uzlu {\em MASTER} se z přijaté hodnoty a aktuálního lokálního času vypočítá doba přenosu jako
$$
D_n = {{T_B - T_A}\over{2}},
$$
kde $T_A$ je čas odeslaný v situaci {\sbf [A]}, tedy na začátku celého procesu a $T_B$ je čas v situaci {\sbf [C]}, tedy po přijetí zprávy od uzlu {\em SLAVE}. Po vypočítání se hodnota odešle do uzlu {\em SLAVE}.
* {\sbf [D]} Uzel {\em SLAVE} přijatou hodnotu zapíše do pole, aby mohla být později použita k výpočtu průměrné doby přenosu $\bar{D}$.
\enditems

Výpočet doby zpoždění předpokládá že je doba přenosu symetrická. Tedy, že průměrné odesílání z {\em MASTER} do {\em SLAVE} trvá stejnou dobu jako odesílání z {\em SLAVE} do {\em MASTER}.

Průběh zprávu pro synchronizaci {\sbf času} je takový, že:

\medskip
\clabel[SchemaSYNCtime]{Schéma synchronizace času}
\picw=16cm \cinspic img/schema-synch-time.png
\caption/f Schéma synchronizace času.
\medskip

\begitems
* {\sbf [A]} Z uzlu {\em MASTER} se odešle zpráva s lokálním časem do uzlu {\em SLAVE}.
* {\sbf [B]} Po přijetí zprávy dojde k výpočtu průměrné chyby $\bar{O}$ a nastavení lokálního času na uzlu {\em SLAVE} podle reference z uzlu {\em MASTER}. Průměrná chyba se počítá s užitím klouzavého průměru jako 
$$
\bar{O} = \bar{O} O_n = \bar{O} (T_S - T_M - \bar{D}),
$$
kde $T_M$ je čas odeslaný z uzlu {\em MASTER} a $T_S$ je aktulaní hodnota času v uzlu {\em SLAVE}.

Čas se následně nastaví v závislosti na velikosti odchylky. Pokud je větší než konstanta $\bar{O} > | k |$,\fnote{Chyba je způsobena především rozdílem rychlosti běhu oscilátorů v zařízeních. Podle výrobce může odchylka dosahovat až ±10 ppm. Pokud je tedy hodnota chyby větší než cca 100 µs, jedná se o chybu v době přenosu. Proto v takové situaci nastavíme maximální hodnotu rovnou na velikost konstanty. V našem případě tedy 100 µs nebo -100 µs, podle orientace.} hodnota hodin je nastavena jako:

$$
T_S = T_M + \bar{D} \pm k.
$$

V případě, že $\bar{O} \leq | k |$, pak je čas nastaví jako:

$$
T_S = T_M + \bar{D} + \bar{O}.
$$
\enditems

\secc Simulace fungování algoritmu

Pro ověření toho, zdali navržený algoritmus splňuje definovanou podmínku přesnosti synchronizace (1 ms), jsem připravil simulaci. Simulace je naprogramovaná v jazyce C. Implementaci si je možné prohlédnout v repozitáři projektu.\fnote{Tato simulace je uložena konkrétně na adrese \url{https://github.com/petrkucerak/rafting-button/tree/main/code/simulation}.} Simulace se skládá z hlavních třech částí:

\begitems
* inicializace prostředku a konfigurace parametrů simulace,
* smyčka realizující samotný běh simulace
* a rutina pro vyčištění alokovaných prostředků.
\enditems

V simulaci je možné {\sbf měnit parametry} nastavující:

\begitems
* dobu simulace (udávaná v µs),
* počet uzlů (maximální počet je 255),
* počáteční čas simulace,
* status uzlu,\fnote{Standartě je jeden z uzlů v režimu {\em MASTER} a ostatní v režimu {\em SLAVE}.}
* chybu oscilátoru na každém z uzlů,
* počáteční čas času uzlů, (udávaný v µs),
* dobu přenosu zprávy mezi uzly,
* velikost pole pro výpočet průměrného zpoždění,
* konstantu pro určení maximální odchylky.
\enditems

Běh simulace pak probíhá jako smyčka omezená dobou. Běh jednoho cyklu představuje dobu 1 µs. V prvním kroku se nastaví náhodné zpoždění pro daný běh na všech uzlech. Druhý inkrementuje lokální hodiny na všech uzlech a realizuje připadnou chyby oscilátoru. Třetí krok na všech uzlech spustí funkci $"process_pipe()"$, která realizuje zpoždění při odesílání zpráv, resp. zkontroluje jestli nějaká ze zpráv nedosáhla požadované doby odesílání. Pokud ano, odešle ji do fronty na cílový uzel. Čtvrtý krok tvoří stavový automat, který se stará o odbavení příchozích zpráv na každém z uzlů. Tento proces funguje podle algoritmu pro synchronizaci času popsaného v předchozí kapitole \ref[DatilAlgDescrp]. Pátý krok odesílá inicializační zprávy pro konkrétní procesy, tedy synchronizaci doby přenosu a času. Synchronizace času se spouští jednou za 500 ms a synchronizace doby zpoždění jednou za 100 ms. V případě definovaní makra $"BUILD_REPORT"$ se v předposledním kroku vypíší hodnoty do log souboru, z kterého jsou následně generovaný grafy. Pro efektivitu velikosti logovacího souboru jsou vypisovány pouze cykly, které obsahují změnu. Pro každý uzel krom uzlu {\em MASTER} se vypisují se tři hodnoty, konkrétně průměrné zpoždění, velikost chyby a rozdíl času v uzlu {\em MASTER} a daného {\em SLAVE} uzlu. Na závěr každého běhy cyklu je inkrementovaný čas běhu simulace.


Odesílání zpráv se zpožděním je realizováno pomocí prioritní fronty nazývané {\em pipe} a fronty obsahující příchozí zprávy. Každý uzel má své tyto dvě struktury. Celý proces je ilustrován v schématu \ref[SchemaOdesilaniZpravVSimulaci]. Probíhá tak, že dojde k odeslání zprávy pomocí funkce $"send_message()"$. Tato funkce alokuje paměť pro novou zprávu a vloží zprávu do prioritní fronty {\em pipe}. Prioritu určuje doba odesílání, konkrétně čím nižší hodnota, tím dříve bude zpráva zpracována. Pokud už uplynula doba odesílání odesílání, zpráva je vyjmuta z {\em pipe} a vložena do {\em queue} na cílovém uzlu, na které jsou uchovávány příchozí zprávy.

\medskip
\clabel[SchemaOdesilaniZpravVSimulaci]{Schéma odesílání zpráv v simulaci}
\picw=16cm \cinspic img/schema-odesilani-zprav-v-simulaci.png
\caption/f Schéma odesílání zpráv v simulaci.
\medskip

Výsledky simulace je možné vizualizovat pomocí třech python skriptů, které se nescházejí v repozitáři simulace. 

První $"visualizeO.py"$ zobrazuje velikost chyby $\bar{O}$ v závislosti na čase pro 3 {\em SLAVE} uzly, umožňuje zobrazit maximální a minimální akceptovatelnou chybu a střední hodnotu všech vypsaných hodnot.

Druhý skript $"visualizeRTT.py"$ zobrazuje průměrnou hodnotu doby přenosu $\bar{D}$ v závislosti na čase pro 3 {\em SLAVE} uzly a umožňuje zobrazit střední hodnotu všech vypsaných hodnot.

Třetí soubor se souborem $"visualizeTIME.py"$ zobrazuje rozdíl uzlu {\em MASTER} a {\em SLAVE} v závislosti na čase simulace pro 3 {\em SLAVE} uzly a umožňuje zobrazit střední hodnotu vypsaných hodnot.

\label[getsimparameters]
\secc Získání parametrů pro simulaci

Pro spuštění simulace, je třeba znát latenci, resp. reálnou dobu odesílání zpráv mezi zařízeními. K tomu jsem připravil zapojení, které funguj tak, že propojuje ESP32 zařízení vodičem, který synchronizuje jejich vnitřní hodiny a je ho možné dohledat v repozitáři projektu.\fnote{\url{https://github.com/petrkucerak/rafting-button/tree/main/code/esp-now-parameters}}

Měřící sestava obsahuje 3 ESP32 zařízení a jedno STM32.\fnote{Konkrétně se jedná o STM32G431KB, které se na ČVUT FEL používá k výuce předmětu LPE. Schéma a realizace zapojení je dostupné v příloze \ref[latencyZapojeniSchematic] a \ref[latencyZapojeni].} STM32 generuje pomocí PWM pulz, který slouží k synchronizaci hodin v distribuovaném systému. ESP32 mezi sebou vysílají zprávy, pomocí nichž se spočítá doba latence.

Měření latence probíhá přesně následujícím způsobem.

\begitems
* Zařízení A odešle do zařízení B a C zprávu s časem odeslání.
* Zařízení B a C zprávu přijmou a spočítají latenci, tedy dobu od odeslání (přesněji zapsání synchronizovaného času do zprávy) do přijmutí zprávy (spuštění callback funkce a provedení výpočtu latence). Latence se počítá jako:
$$
t_l = T_{B,C} - T_A,
$$
kde $T_l$ je velikost latence, $T_A$ čas ve zprávě, resp. čas odeslání a $T_{B,C}$ je čas přijmutí zprávy.
\enditems

Čas je v ESP32 synchronizován pomocí pulzů z PWM generovaného STM32. To tak, že při registraci náběžné hrany na vstupním pinu (nastaveno na $"GPIO_NUM_21"$) se generuje přerušení (ISR), které uloží aktuální hodnotu globálního času od spuštění a prohlásí ji za výchozí čas synchronizace ($T_s$). Čas DS se následně počít jako

$$
T_{DS} = T_g - T_s,
$$
kde $T_{DS}$ je čas synchronizovaný v DS, $T_g$ je doba běhu daného zařízení a $T_s$ je čas synchronizace času.

Čas je synchronizován s průměrnou odchylkou okolo 173 µs. Tato hodnota byla určena měřením kdy je generován pulz o frekvenci 1 Hz, perioda je tedy 1 s. A {\em ISR handler} funkce vždy spočítá čas od předchozího běhu a vynuluje $T_s$. Zpoždění je dáno režijními náklady běhu procesoru. Maximální odchylka byla určená také měřením a při běhu 24 min a 18 s dosáhla maximální hodnoty 810 µs.\fnote{Původně jsem se domníval, že overhead je veliký především kvůli funkci $"esp_timer_get_time()"$ z důvodu dohledané diskuze \url{https://esp32.com/viewtopic.php?t=16228}. Experimentem jsem ale ověřil, že tato funkce není hlavní brzdou při měření. Prodlevu se mi ale povedlo snížit přetaktováním na 240 MHz a optimalizací kódu.
  
Nepřesnost v tomto měření může způsobit i skutečnost, že nevím s jakou přesností je generován referenční signál.}

K měření jsem využil obou velikostí ESP32 modulů a jejich doba odesílání se nelišila.

Měření jsem spustil ve dvou scénářích. Lišily se pouze časem běhu. Scénář A trval přibližně 6,5 min a scénář B přibližně 37 min. Výsledné hodnoty jsou totožné, pouze se liší množstvím odeslaných a přijatých zpráv.

\midinsert \clabel[LatencyMeasurement]{Parametry měření latence}
\ctable{lrrrr}{
\hfil {\sbf měření} & {\sbf zařízení} & {\sbf mean} & {\sbf max} & {\sbf min} \crl
{\sbf A} & COM6 & 1308.59 µs & 14944 µs & 899 µs\cr
{\sbf A} & COM7 & 1256.00 µs & 19471 µs & 883 µs\cr
{\sbf B} & COM6 & 1152.03 µs & 13239 µs & 893 µs\cr
{\sbf B} & COM7 & 1134.67 µs & 25143 µs & 871 µs\cr
}
\caption/t Parametry měření latence.
\endinsert

Pokud se na naměřená data chceme podívat z pohledu četnosti pro jednotlivé zpoždění, bude nejlepší využít histogramů \ref[latencyA] a \ref[latencyB]. Histogram zobrazuje oblast od 900 µs až po 1200 µs. Počet zpráv pro vyšší zpoždění je oproti tomuto intervalu zanedbatelný, proto vyšší zpoždění není zobrazeno.

Zajímavé jsou vždy 2 oblasti vyšší četnosti. Ty si i na základě detailního studování logů\fnote{Možné dohledat v repozitáři projektu.} vysvětluji tak, že vždy první odeslání trvá delší dobu. Testovací vysílání totiž funguje tak, že z uzlu {\em MASTER} vždy odešle 3x2 zprávy, resp. 3x odešle zprávu do uzlu COM6 a COM7. První odesílání je vždy do uzlu COM6. Poté se počká na synchronizaci času a měření se opakuje.

Z měření vyplývá, že {\sbf průměrná doba zpoždění} {\em unicast} vysílání se pohybuje mezi 900 µs a 1050 µs.\fnote{Dle skriptu $"distribution.py"$ víme, že přesně 86,7\% zpráv byla odeslána v tomto časovém intervalu.}

\secc Simulace s reálnými parametry

Simulace byla prováděna s konfigurací, kdy

\begitems
* doba simulace byla 10 min (bylo provedeno 6000 synchronizací doby odesílání a 2000 synchronizací času),
* pro simulaci byly užity 4 uzle,
* {\em MASTER} uzel začínal v čase nula, ostatní uzly na náhodném čase v rozmezí 100~µs až 1500~µs,
* doba zpoždění zpráv byla náhodně zvolena pro každé odesílání a to v rozsahu od 900 µs až po 1050 µs,
* a chyba oscilátorů se pohybovala náhodně mezi maximální chybou ±1~ppm až ±10~ppm.
\enditems

Jsem si vědom, že simulace nezohledňuje veškerou problematiku. To především, že rozdělení odesílání zprávy není náhodné, nýbrž se chová dle výsledků kapitoly \ref[getsimparameters]. Teoreticky při běhu může také dojít k tomu, že jedna situace nastane vícekrát. To v případě, kdy během synchronizace bude čas nastaven dozadu. Jsem si této chyby vědom. Nicméně se v mém případě nejedná o kritickou aplikaci a synchronizace dosahuje takových výsledků přesnosti, že je vysoce nepravděpodobné, že by k této chybě došlo.

Výsledky chování simulace zobrazují 3 grafy. První z nich \ref[latencyO] ukazuje průměrnou chybu $\bar{O}$ v závislosti na čase a střední hodnotu chyb. Ty se pohybuji v blízkém okolí nuly, jak bychom očekávali. Druhý graf \ref[latencyRTT] zobrazuje průměrnou hodnotu doby přenosu $\bar{D}$ v závislosti na čase. Vidíme, že k synchronizaci dojde poměrně rychle. Třetí a pro splnění stanovených parametrů nejvíce důležitý graf \ref[latencyTIME] zobrazuje rozdíl času mezi {\em MASTER} uzlem a {\em SLAVE} uzlem. Střední hodnota tohoto ukazatele je okolo nuly a simulace dosahuje maximální odchylky do ±0,25 ms, což hravě splňuje náš limit 1 ms.

Ze simulace vyplývá, že navržený algoritmus dle simulace {\sbf splňuje stanovený požadavek přesnosti synchronizace času}, tedy 1~ms.